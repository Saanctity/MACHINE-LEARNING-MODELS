{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWn30PDkW9oX"
      },
      "outputs": [],
      "source": [
        "# Thyroid Cancer Recurrence Prediction System\n",
        "# Clean, Production-Ready Code - No Data Leakage\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"THYROID CANCER RECURRENCE PREDICTION SYSTEM\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 1. LOAD DATA\n",
        "# ========================\n",
        "from google.colab import files\n",
        "print(\"\\n Upload your thyroid cancer dataset (CSV):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "df = pd.read_csv(list(uploaded.keys())[0])\n",
        "print(f\"\\n Loaded: {df.shape[0]} samples, {df.shape[1]} features\")\n"
      ],
      "metadata": {
        "id": "EaGzSQHgpt_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 2. REMOVE DATA LEAKAGE\n",
        "# ========================\n",
        "# These features are measured AFTER/DURING recurrence detection\n",
        "LEAKY_FEATURES = ['Response', 'Stage', 'T', 'N', 'M']\n",
        "\n",
        "print(f\"\\n  Removing leaky features: {[f for f in LEAKY_FEATURES if f in df.columns]}\")\n",
        "df_clean = df.drop(columns=[f for f in LEAKY_FEATURES if f in df.columns])\n"
      ],
      "metadata": {
        "id": "iWRI840Kpx2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 3. PREPROCESS\n",
        "# ========================\n",
        "# Handle missing values\n",
        "df_clean = df_clean.fillna(df_clean.mode().iloc[0])\n",
        "\n",
        "# Encode categorical variables\n",
        "le = LabelEncoder()\n",
        "for col in df_clean.select_dtypes(include=['object']).columns:\n",
        "    df_clean[col] = le.fit_transform(df_clean[col].astype(str))\n",
        "\n",
        "# Split features and target\n",
        "X = df_clean.drop('Recurred', axis=1)\n",
        "y = df_clean['Recurred']\n",
        "\n",
        "print(f\" Clean dataset: {X.shape[1]} features\")\n",
        "print(f\"   Recurrence rate: {y.mean()*100:.1f}%\")\n",
        "\n",
        "# Train-test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "XpxQthSnpyD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 4. TRAIN MODELS\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, C=0.1),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=8,\n",
        "                                           min_samples_split=10, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=200, max_depth=4,\n",
        "                                                    learning_rate=0.05, random_state=42),\n",
        "    'XGBoost': XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.05,\n",
        "                            random_state=42, n_jobs=-1, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "results = {}\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n Training {name}...\")\n",
        "\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train,\n",
        "                               cv=skf, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'y_pred': y_pred,\n",
        "        'y_proba': y_pred_proba,\n",
        "        'auc': auc,\n",
        "        'accuracy': acc,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std()\n",
        "    }\n",
        "\n",
        "    print(f\"   Test AUC: {auc:.4f} | Accuracy: {acc:.4f}\")\n",
        "    print(f\"   CV AUC: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n"
      ],
      "metadata": {
        "id": "Px9yDiVIp7D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 5. ENSEMBLE MODEL\n",
        "# ========================\n",
        "print(\"\\n Creating Ensemble (Voting Classifier)...\")\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', models['Random Forest']),\n",
        "        ('gb', models['Gradient Boosting']),\n",
        "        ('xgb', models['XGBoost'])\n",
        "    ],\n",
        "    voting='soft',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ensemble.fit(X_train_scaled, y_train)\n",
        "y_pred_ensemble = ensemble.predict(X_test_scaled)\n",
        "y_proba_ensemble = ensemble.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "auc_ensemble = roc_auc_score(y_test, y_proba_ensemble)\n",
        "acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
        "cv_ensemble = cross_val_score(ensemble, X_train_scaled, y_train,\n",
        "                              cv=skf, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "results['Ensemble'] = {\n",
        "    'model': ensemble,\n",
        "    'y_pred': y_pred_ensemble,\n",
        "    'y_proba': y_proba_ensemble,\n",
        "    'auc': auc_ensemble,\n",
        "    'accuracy': acc_ensemble,\n",
        "    'cv_mean': cv_ensemble.mean(),\n",
        "    'cv_std': cv_ensemble.std()\n",
        "}\n",
        "\n",
        "print(f\"   Test AUC: {auc_ensemble:.4f} | Accuracy: {acc_ensemble:.4f}\")\n",
        "print(f\"   CV AUC: {cv_ensemble.mean():.4f} (Â±{cv_ensemble.std():.4f})\")\n",
        "\n",
        "# Select best model\n",
        "best_name = max(results, key=lambda x: results[x]['auc'])\n",
        "best_model = results[best_name]\n",
        "\n",
        "print(f\"\\n BEST MODEL: {best_name}\")\n",
        "print(f\"   AUC: {best_model['auc']:.4f}\")\n"
      ],
      "metadata": {
        "id": "F_Rny3ewp_St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 6. EVALUATION\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(y_test, best_model['y_pred'],\n",
        "                          target_names=['No Recurrence', 'Recurrence']))\n"
      ],
      "metadata": {
        "id": "9WtcUvxZqDPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 7. VISUALIZATIONS\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING VISUALIZATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Model Comparison\n",
        "ax1 = axes[0, 0]\n",
        "model_names = list(results.keys())\n",
        "auc_scores = [results[m]['auc'] for m in model_names]\n",
        "colors = ['#27ae60' if m == best_name else '#3498db' for m in model_names]\n",
        "bars = ax1.barh(model_names, auc_scores, color=colors, alpha=0.8)\n",
        "ax1.set_xlabel('AUC Score', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlim([0.5, 1.0])\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "for i, (bar, score) in enumerate(zip(bars, auc_scores)):\n",
        "    ax1.text(score + 0.01, i, f'{score:.4f}', va='center', fontweight='bold')\n",
        "\n",
        "# 2. Confusion Matrix\n",
        "ax2 = axes[0, 1]\n",
        "cm = confusion_matrix(y_test, best_model['y_pred'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
        "           cbar_kws={'label': 'Count'}, annot_kws={'size': 16, 'weight': 'bold'})\n",
        "ax2.set_title(f'Confusion Matrix - {best_name}', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
        "ax2.set_xticklabels(['No Recurrence', 'Recurrence'])\n",
        "ax2.set_yticklabels(['No Recurrence', 'Recurrence'])\n",
        "\n",
        "# 3. ROC Curves\n",
        "ax3 = axes[1, 0]\n",
        "for name in model_names:\n",
        "    fpr, tpr, _ = roc_curve(y_test, results[name]['y_proba'])\n",
        "    auc = results[name]['auc']\n",
        "    lw = 3 if name == best_name else 1.5\n",
        "    ls = '-' if name == best_name else '--'\n",
        "    ax3.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})',\n",
        "            linewidth=lw, linestyle=ls)\n",
        "ax3.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5)\n",
        "ax3.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
        "ax3.set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
        "ax3.legend(loc='lower right', fontsize=9)\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. Feature Importance\n",
        "ax4 = axes[1, 1]\n",
        "if best_name != 'Ensemble':\n",
        "    base_model = best_model['model']\n",
        "else:\n",
        "    base_model = best_model['model'].estimators_[1]  # Use GB from ensemble\n",
        "\n",
        "if hasattr(base_model, 'feature_importances_'):\n",
        "    importances = base_model.feature_importances_\n",
        "    indices = np.argsort(importances)[-10:]\n",
        "    colors_fi = plt.cm.viridis(importances[indices] / importances[indices].max())\n",
        "    ax4.barh(range(len(indices)), importances[indices], color=colors_fi)\n",
        "    ax4.set_yticks(range(len(indices)))\n",
        "    ax4.set_yticklabels([X.columns[i] for i in indices])\n",
        "    ax4.set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
        "    ax4.set_title(f'Top 10 Features - {best_name}', fontsize=14, fontweight='bold')\n",
        "    ax4.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dwh0dOwXqLJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# 8. SUMMARY\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n Dataset:\")\n",
        "print(f\"   Samples: {len(df_clean)} | Features: {X.shape[1]}\")\n",
        "print(f\"   Recurrence Rate: {y.mean()*100:.1f}%\")\n",
        "print(f\"   Train/Test: {len(y_train)}/{len(y_test)}\")\n",
        "\n",
        "print(f\"\\n Best Model: {best_name}\")\n",
        "print(f\"   Test AUC: {best_model['auc']:.4f}\")\n",
        "print(f\"   Test Accuracy: {best_model['accuracy']:.4f}\")\n",
        "print(f\"   CV AUC: {best_model['cv_mean']:.4f} (Â±{best_model['cv_std']:.4f})\")\n",
        "\n",
        "print(f\"\\nðŸ’¡ Top Predictive Features:\")\n",
        "if hasattr(base_model, 'feature_importances_'):\n",
        "    top_idx = np.argsort(base_model.feature_importances_)[-5:][::-1]\n",
        "    for i, idx in enumerate(top_idx, 1):\n",
        "        feat_name = X.columns[idx]\n",
        "        importance = base_model.feature_importances_[idx]\n",
        "        print(f\"   {i}. {feat_name}: {importance:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "opWtGVP1qi2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}