{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp6qyFS9KJv5"
      },
      "outputs": [],
      "source": [
        "# Liver Cirrhosis Stage Detection\n",
        "# Predicting histologic stage of disease (1, 2, or 3) from patient data\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "print(\"=\" * 80)\n",
        "print(\"LIVER CIRRHOSIS STAGE DETECTION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n[1] Loading Dataset...\")\n",
        "\n",
        "df = pd.read_csv('liver_cirrhosis.csv')\n",
        "print(f\"✓ Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "# Display basic info\n",
        "print(\"\\n[2] Dataset Overview\")\n",
        "print(\"-\" * 80)\n",
        "print(df.head())\n",
        "print(\"\\nTarget Distribution:\")\n",
        "print(df['Stage'].value_counts().sort_index())\n",
        "\n",
        "# Check missing values\n",
        "print(\"\\n[3] Missing Values Check\")\n",
        "print(\"-\" * 80)\n",
        "missing = df.isnull().sum()\n",
        "if missing.sum() > 0:\n",
        "    print(missing[missing > 0])\n",
        "else:\n",
        "    print(\"✓ No missing values!\")\n"
      ],
      "metadata": {
        "id": "-LWQW7ppLFVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizations\n",
        "print(\"\\n[4] Visualizations\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Stage distribution\n",
        "stage_counts = df['Stage'].value_counts().sort_index()\n",
        "axes[0].bar(stage_counts.index, stage_counts.values, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
        "axes[0].set_xlabel('Stage')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_title('Liver Cirrhosis Stage Distribution')\n",
        "axes[0].set_xticks([1, 2, 3])\n",
        "\n",
        "# Pie chart\n",
        "axes[1].pie(stage_counts.values, labels=[f'Stage {i}' for i in stage_counts.index],\n",
        "            autopct='%1.1f%%', colors=['#3498db', '#2ecc71', '#e74c3c'])\n",
        "axes[1].set_title('Stage Distribution (%)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QdMkeVRYLZNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key feature distributions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
        "features = ['Bilirubin', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Prothrombin']\n",
        "for idx, feat in enumerate(features):\n",
        "    row, col = idx // 3, idx % 3\n",
        "    for stage in [1, 2, 3]:\n",
        "        axes[row, col].hist(df[df['Stage'] == stage][feat].dropna(),\n",
        "                           alpha=0.5, label=f'Stage {stage}', bins=20)\n",
        "    axes[row, col].set_xlabel(feat)\n",
        "    axes[row, col].set_ylabel('Frequency')\n",
        "    axes[row, col].legend()\n",
        "    axes[row, col].set_title(f'{feat} by Stage')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x2PBd3d9LitA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "print(\"\\n[5] Data Preprocessing\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Stage', axis=1)\n",
        "y = df['Stage']\n",
        "\n",
        "# Encode categorical variables\n",
        "print(\"Encoding categorical variables...\")\n",
        "label_encoders = {}\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(f\"✓ Encoded {len(categorical_cols)} categorical columns\")\n",
        "\n",
        "# Handle missing values if any\n",
        "if X.isnull().sum().sum() > 0:\n",
        "    print(\"Filling missing values with median...\")\n",
        "    X = X.fillna(X.median())\n",
        "\n",
        "# Feature scaling\n",
        "print(\"Scaling features...\")\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"✓ Train set: {X_train.shape[0]} samples\")\n",
        "print(f\"✓ Test set: {X_test.shape[0]} samples\")"
      ],
      "metadata": {
        "id": "ze1N1aitLtJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "print(\"\\n[6] Model Training - Random Forest\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"✓ Model trained successfully!\")\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"✓ Cross-validation accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
      ],
      "metadata": {
        "id": "nrkwDpg8Lzid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "print(\"\\n[7] Model Evaluation\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "train_acc = rf_model.score(X_train, y_train)\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_acc:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Stage 1', 'Stage 2', 'Stage 3']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Stage 1', 'Stage 2', 'Stage 3'],\n",
        "            yticklabels=['Stage 1', 'Stage 2', 'Stage 3'])\n",
        "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2_8bjQvTMOCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "print(\"\\n[8] Feature Importance Analysis\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Important Features:\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_features = feature_importance.head(15)\n",
        "plt.barh(range(len(top_features)), top_features['Importance'])\n",
        "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 15 Feature Importance', fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BNrNOtWQMT0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Predictions\n",
        "print(\"\\n[9] Sample Predictions\")\n",
        "print(\"-\" * 80)\n",
        "sample_predictions = pd.DataFrame({\n",
        "    'Actual': y_test.values[:10],\n",
        "    'Predicted': y_pred[:10]\n",
        "})\n",
        "print(sample_predictions)\n",
        "\n",
        "# Final Summary\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MODEL SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Model: Random Forest Classifier\")\n",
        "print(f\"Training Samples: {len(X_train)}\")\n",
        "print(f\"Testing Samples: {len(X_test)}\")\n",
        "print(f\"Number of Features: {X.shape[1]}\")\n",
        "print(f\"Target Classes: {sorted(y.unique())}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"=\" * 80)\n",
        "print(\"✓ Model ready for deployment!\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "wcRuXL6WMZnt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}