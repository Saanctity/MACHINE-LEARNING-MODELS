{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xoq1ory1OFZ8"
      },
      "outputs": [],
      "source": [
        "# Vehicle Price Prediction Model\n",
        "# Complete ML pipeline for predicting vehicle prices\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. LOAD AND EXPLORE DATA\n",
        "# ==============================================================================\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"VEHICLE PRICE PREDICTION - DATA EXPLORATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nDataset Shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(f\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(f\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(f\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "X5F88meBJ4VA",
        "outputId": "f7a346e6-8c13-4628-8998-931495c8162c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2035831958.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. DATA CLEANING AND PREPROCESSING\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA CLEANING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Remove rows with missing or zero prices\n",
        "df = df[df['price'].notna() & (df['price'] > 0)]\n",
        "\n",
        "# Handle missing values\n",
        "df['cylinders'].fillna(df['cylinders'].median(), inplace=True)\n",
        "df['mileage'].fillna(df['mileage'].median(), inplace=True)\n",
        "df['doors'].fillna(4, inplace=True)\n",
        "df['year'].fillna(df['year'].median(), inplace=True)\n",
        "\n",
        "# Fill categorical missing values\n",
        "categorical_cols = ['make', 'model', 'fuel', 'transmission', 'body', 'drivetrain',\n",
        "                    'exterior_color', 'interior_color', 'trim']\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns:\n",
        "        df[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Remove outliers (prices outside reasonable range)\n",
        "df = df[(df['price'] >= 1000) & (df['price'] <= 500000)]\n",
        "df = df[(df['year'] >= 1990) & (df['year'] <= 2025)]\n",
        "df = df[df['mileage'] <= 500000]\n",
        "\n",
        "print(f\"\\nCleaned Dataset Shape: {df.shape}\")\n",
        "print(f\"Price Range: ${df['price'].min():.2f} - ${df['price'].max():.2f}\")\n",
        "print(f\"Average Price: ${df['price'].mean():.2f}\")\n"
      ],
      "metadata": {
        "id": "SZT-R4ngKE6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. FEATURE ENGINEERING\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create new features\n",
        "current_year = 2025\n",
        "df['vehicle_age'] = current_year - df['year']\n",
        "df['mileage_per_year'] = df['mileage'] / (df['vehicle_age'] + 1)\n",
        "\n",
        "# Luxury brand indicator\n",
        "luxury_brands = ['BMW', 'Mercedes-Benz', 'Audi', 'Lexus', 'Porsche', 'Tesla',\n",
        "                 'Land Rover', 'Jaguar', 'Bentley', 'Maserati', 'Cadillac']\n",
        "df['is_luxury'] = df['make'].isin(luxury_brands).astype(int)\n",
        "\n",
        "# Electric vehicle indicator\n",
        "df['is_electric'] = (df['fuel'] == 'Electric').astype(int)\n",
        "\n",
        "# All-wheel/Four-wheel drive indicator\n",
        "df['is_awd_4wd'] = df['drivetrain'].str.contains('All-wheel|Four-wheel', case=False, na=False).astype(int)\n",
        "\n",
        "# Body type categories\n",
        "df['is_suv'] = (df['body'] == 'SUV').astype(int)\n",
        "df['is_truck'] = df['body'].str.contains('Truck', case=False, na=False).astype(int)\n",
        "df['is_sedan'] = (df['body'] == 'Sedan').astype(int)\n",
        "\n",
        "print(f\"New Features Created:\")\n",
        "print(f\"  - vehicle_age\")\n",
        "print(f\"  - mileage_per_year\")\n",
        "print(f\"  - is_luxury\")\n",
        "print(f\"  - is_electric\")\n",
        "print(f\"  - is_awd_4wd\")\n",
        "print(f\"  - Body type indicators\")"
      ],
      "metadata": {
        "id": "-M5bvRKCKJgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. EXPLORATORY DATA ANALYSIS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Price distribution\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.hist(df['price'], bins=50, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Price ($)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Price Distribution')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(df['vehicle_age'], df['price'], alpha=0.3, color='coral')\n",
        "plt.xlabel('Vehicle Age (years)')\n",
        "plt.ylabel('Price ($)')\n",
        "plt.title('Price vs Vehicle Age')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(df['mileage'], df['price'], alpha=0.3, color='lightgreen')\n",
        "plt.xlabel('Mileage')\n",
        "plt.ylabel('Price ($)')\n",
        "plt.title('Price vs Mileage')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Average price by make (top 10)\n",
        "top_makes = df.groupby('make')['price'].agg(['mean', 'count']).sort_values('count', ascending=False).head(10)\n",
        "print(\"\\nTop 10 Makes by Volume:\")\n",
        "print(top_makes)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "top_makes['mean'].plot(kind='bar', color='steelblue')\n",
        "plt.xlabel('Make')\n",
        "plt.ylabel('Average Price ($)')\n",
        "plt.title('Average Price by Top 10 Makes')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation analysis\n",
        "numeric_features = ['year', 'price', 'cylinders', 'mileage', 'doors', 'vehicle_age',\n",
        "                    'mileage_per_year', 'is_luxury', 'is_electric', 'is_awd_4wd']\n",
        "correlation_matrix = df[numeric_features].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nCorrelation with Price:\")\n",
        "print(correlation_matrix['price'].sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "3Y0a5hNuKSSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. PREPARE DATA FOR MODELING\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREPARING DATA FOR MODELING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Select features for modeling\n",
        "feature_cols = ['year', 'cylinders', 'mileage', 'doors', 'vehicle_age',\n",
        "                'mileage_per_year', 'is_luxury', 'is_electric', 'is_awd_4wd',\n",
        "                'is_suv', 'is_truck', 'is_sedan']\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_features = ['make', 'fuel', 'transmission', 'body', 'drivetrain']\n",
        "\n",
        "for col in categorical_features:\n",
        "    if col in df.columns:\n",
        "        le = LabelEncoder()\n",
        "        df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "        feature_cols.append(f'{col}_encoded')\n",
        "\n",
        "# Prepare X and y\n",
        "X = df[feature_cols]\n",
        "y = df['price']\n",
        "\n",
        "print(f\"\\nFeatures used: {len(feature_cols)}\")\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "PhO2Ka5vKV0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 6. MODEL TRAINING AND EVALUATION\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL TRAINING AND EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Train model\n",
        "    if name == 'Linear Regression':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2,\n",
        "        'MAPE': mape,\n",
        "        'predictions': y_pred\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"  Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "    print(f\"  Root Mean Squared Error (RMSE): ${rmse:,.2f}\")\n",
        "    print(f\"  R² Score: {r2:.4f} ({r2*100:.2f}%)\")\n",
        "    print(f\"  Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n"
      ],
      "metadata": {
        "id": "1dp8h-SaKaOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 7. BEST MODEL SELECTION AND FEATURE IMPORTANCE\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Compare models\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': results.keys(),\n",
        "    'MAE': [results[m]['MAE'] for m in results.keys()],\n",
        "    'RMSE': [results[m]['RMSE'] for m in results.keys()],\n",
        "    'R² Score': [results[m]['R2'] for m in results.keys()],\n",
        "    'MAPE (%)': [results[m]['MAPE'] for m in results.keys()]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "comparison_df.plot(x='Model', y='MAE', kind='bar', ax=axes[0], color='coral', legend=False)\n",
        "axes[0].set_title('Mean Absolute Error')\n",
        "axes[0].set_ylabel('MAE ($)')\n",
        "\n",
        "comparison_df.plot(x='Model', y='R² Score', kind='bar', ax=axes[1], color='skyblue', legend=False)\n",
        "axes[1].set_title('R² Score')\n",
        "axes[1].set_ylabel('R² Score')\n",
        "\n",
        "comparison_df.plot(x='Model', y='MAPE (%)', kind='bar', ax=axes[2], color='lightgreen', legend=False)\n",
        "axes[2].set_title('Mean Absolute Percentage Error')\n",
        "axes[2].set_ylabel('MAPE (%)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature importance from Random Forest\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FEATURE IMPORTANCE (Random Forest)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "rf_model = models['Random Forest']\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance.head(10), x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Top 10 Most Important Features')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RSYGJY7AKd89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 8. PREDICTION VISUALIZATION\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREDICTION VISUALIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "best_model_name = comparison_df.loc[comparison_df['R² Score'].idxmax(), 'Model']\n",
        "best_predictions = results[best_model_name]['predictions']\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, best_predictions, alpha=0.5, color='steelblue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Price ($)')\n",
        "plt.ylabel('Predicted Price ($)')\n",
        "plt.title(f'Actual vs Predicted Prices\\n({best_model_name})')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y_test - best_predictions\n",
        "plt.scatter(best_predictions, residuals, alpha=0.5, color='coral')\n",
        "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "plt.xlabel('Predicted Price ($)')\n",
        "plt.ylabel('Residuals ($)')\n",
        "plt.title('Residual Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CK8doORmKhI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 9. SAMPLE PREDICTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAMPLE PREDICTIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "sample_results = pd.DataFrame({\n",
        "    'Actual Price': y_test.values[:10],\n",
        "    'Predicted Price': best_predictions[:10],\n",
        "    'Error': np.abs(y_test.values[:10] - best_predictions[:10]),\n",
        "    'Error %': np.abs((y_test.values[:10] - best_predictions[:10]) / y_test.values[:10] * 100)\n",
        "})\n",
        "\n",
        "print(\"\\nFirst 10 Test Set Predictions:\")\n",
        "print(sample_results.to_string(index=False))"
      ],
      "metadata": {
        "id": "XnctofOTKkXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 10. FINAL SUMMARY\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"R² Score: {results[best_model_name]['R2']:.4f} ({results[best_model_name]['R2']*100:.2f}%)\")\n",
        "print(f\"Mean Absolute Error: ${results[best_model_name]['MAE']:,.2f}\")\n",
        "print(f\"RMSE: ${results[best_model_name]['RMSE']:,.2f}\")\n",
        "print(f\"MAPE: {results[best_model_name]['MAPE']:.2f}%\")\n",
        "\n",
        "print(f\"\\nDataset Size: {len(df)} vehicles\")\n",
        "print(f\"Features Used: {len(feature_cols)}\")\n",
        "print(f\"Training/Test Split: 80/20\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL TRAINING COMPLETE\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "08cLGoKpKsKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}