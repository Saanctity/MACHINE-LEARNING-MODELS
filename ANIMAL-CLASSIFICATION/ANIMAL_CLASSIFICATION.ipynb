{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa2MwOdhmbAd",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Animal Image Classification Project\n",
        "# Objective: Build a system that can identify animals in given images using Neural Networks and Transfer Learning\n",
        "# Dataset: 15 animal classes with 30 images each (450 total images)\n",
        "\n",
        "# Install required packages\n",
        "!pip install tensorflow opencv-python matplotlib seaborn scikit-learn pillow -q\n",
        "\n",
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for visualizations\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üêæ Animal Classification Project\")\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== DATA SETUP ====================\n",
        "\n",
        "# Upload and extract the dataset ZIP file\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "print(\"üìÅ Upload your dataset folder here:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract the ZIP file\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"üì¶ Extracting {filename}...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(\"‚úÖ Dataset extracted successfully!\")\n",
        "        break\n",
        "\n",
        "# Set dataset path\n",
        "data_path = 'Animal Classification/dataset'\n",
        "\n",
        "# Configuration\n",
        "IMG_SIZE = (160, 160)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "NUM_CLASSES = 15\n",
        "\n",
        "# Animal classes\n",
        "CLASSES = ['Bear', 'Bird', 'Cat', 'Cow', 'Deer', 'Dog', 'Dolphin',\n",
        "          'Elephant', 'Giraffe', 'Horse', 'Kangaroo', 'Lion', 'Panda', 'Tiger', 'Zebra']\n"
      ],
      "metadata": {
        "id": "uMgo8KReM93_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== DATA EXPLORATION ====================\n",
        "\n",
        "def explore_dataset(data_path):\n",
        "    \"\"\"Explore the dataset structure and statistics\"\"\"\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(\"‚ö†Ô∏è  Dataset path not found!\")\n",
        "        return None\n",
        "\n",
        "    print(\"üìä Dataset Overview\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    class_counts = {}\n",
        "    total_images = 0\n",
        "\n",
        "    for class_name in CLASSES:\n",
        "        class_path = os.path.join(data_path, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            count = len([f for f in os.listdir(class_path)\n",
        "                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            class_counts[class_name] = count\n",
        "            total_images += count\n",
        "        else:\n",
        "            class_counts[class_name] = 0\n",
        "\n",
        "    df = pd.DataFrame(list(class_counts.items()), columns=['Animal', 'Count'])\n",
        "    print(f\"Total Images: {total_images}\")\n",
        "    print(f\"Average per class: {total_images // len(CLASSES)}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    bars = plt.bar(df['Animal'], df['Count'], color=sns.color_palette(\"husl\", len(CLASSES)))\n",
        "    plt.title('üêæ Dataset Distribution', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Animal Classes')\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{int(height)}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df\n",
        "\n",
        "# Explore dataset\n",
        "dataset_stats = explore_dataset(data_path)\n"
      ],
      "metadata": {
        "id": "aFvI4ZQmOh2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== DATA PREPROCESSING ====================\n",
        "\n",
        "def create_data_generators():\n",
        "    \"\"\"Create data generators with augmentation\"\"\"\n",
        "\n",
        "    # Data augmentation for training\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.1,\n",
        "        brightness_range=[0.8, 1.2],\n",
        "        validation_split=0.2,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Training generator\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        data_path,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='training',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # Validation generator\n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "        data_path,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='validation',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "# Create data generators\n",
        "print(\"üîÑ Creating data generators...\")\n",
        "train_gen, val_gen = create_data_generators()\n",
        "print(f\"‚úÖ Training samples: {train_gen.samples}\")\n",
        "print(f\"‚úÖ Validation samples: {val_gen.samples}\")"
      ],
      "metadata": {
        "id": "v7U8uIl7QNx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== MODEL BUILDING ====================\n",
        "\n",
        "def create_model():\n",
        "    \"\"\"Create transfer learning model using MobileNetV2\"\"\"\n",
        "\n",
        "    print(\"üß† Building model with MobileNetV2...\")\n",
        "\n",
        "    # Load pre-trained MobileNetV2\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(*IMG_SIZE, 3),\n",
        "        alpha=1.0\n",
        "    )\n",
        "\n",
        "    # Freeze base model initially\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add custom classification head\n",
        "    model = keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ Model created successfully!\")\n",
        "    print(f\"Total parameters: {model.count_params():,}\")\n",
        "\n",
        "    return model, base_model\n",
        "\n",
        "# Create model\n",
        "model, base_model = create_model()\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rj3xcu8QOrDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== TRAINING ====================\n",
        "\n",
        "def create_callbacks():\n",
        "    \"\"\"Create training callbacks\"\"\"\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.3,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return callbacks\n",
        "\n",
        "def train_model(model, train_gen, val_gen, base_model, epochs=EPOCHS):\n",
        "    \"\"\"Train model using transfer learning approach\"\"\"\n",
        "\n",
        "    print(\"üöÄ Starting Training!\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    callbacks = create_callbacks()\n",
        "\n",
        "    # Phase 1: Train classifier head\n",
        "    print(\"üìö Phase 1: Training classifier head...\")\n",
        "\n",
        "    history_1 = model.fit(\n",
        "        train_gen,\n",
        "        steps_per_epoch=train_gen.samples // BATCH_SIZE,\n",
        "        validation_data=val_gen,\n",
        "        validation_steps=val_gen.samples // BATCH_SIZE,\n",
        "        epochs=epochs // 2,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Phase 2: Fine-tuning\n",
        "    print(\"\\nüéØ Phase 2: Fine-tuning model...\")\n",
        "\n",
        "    # Unfreeze top layers of base model\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Fine-tune from this layer onwards\n",
        "    fine_tune_at = len(base_model.layers) - 20\n",
        "\n",
        "    # Freeze all the layers before fine_tune_at\n",
        "    for layer in base_model.layers[:fine_tune_at]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Recompile with lower learning rate\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001/10),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    history_2 = model.fit(\n",
        "        train_gen,\n",
        "        steps_per_epoch=train_gen.samples // BATCH_SIZE,\n",
        "        validation_data=val_gen,\n",
        "        validation_steps=val_gen.samples // BATCH_SIZE,\n",
        "        epochs=epochs - len(history_1.history['loss']),\n",
        "        callbacks=callbacks,\n",
        "        initial_epoch=len(history_1.history['loss']),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Combine histories\n",
        "    history = {}\n",
        "    for key in history_1.history.keys():\n",
        "        history[key] = history_1.history[key] + history_2.history[key]\n",
        "\n",
        "    return history\n",
        "\n",
        "# Train the model\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "history = train_model(model, train_gen, val_gen, base_model)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = (end_time - start_time) / 60\n",
        "print(f\"üéâ Training completed in {training_time:.1f} minutes!\")\n"
      ],
      "metadata": {
        "id": "e6nurcj3Pzwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== RESULTS VISUALIZATION ====================\n",
        "\n",
        "def plot_training_results(history):\n",
        "    \"\"\"Plot training results\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0].plot(history['accuracy'], 'bo-', label='Training Accuracy', linewidth=2)\n",
        "    axes[0].plot(history['val_accuracy'], 'ro-', label='Validation Accuracy', linewidth=2)\n",
        "    axes[0].set_title('üìà Model Accuracy', fontweight='bold')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Loss\n",
        "    axes[1].plot(history['loss'], 'bo-', label='Training Loss', linewidth=2)\n",
        "    axes[1].plot(history['val_loss'], 'ro-', label='Validation Loss', linewidth=2)\n",
        "    axes[1].set_title('üìâ Model Loss', fontweight='bold')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model, val_gen):\n",
        "    \"\"\"Evaluate model performance\"\"\"\n",
        "\n",
        "    print(\"üéØ Evaluating Model Performance...\")\n",
        "\n",
        "    # Get predictions\n",
        "    val_gen.reset()\n",
        "    predictions = model.predict(val_gen, verbose=1)\n",
        "    pred_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = val_gen.classes\n",
        "    class_names = list(val_gen.class_indices.keys())\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nüìä Classification Report:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(classification_report(true_classes, pred_classes, target_names=class_names))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(true_classes, pred_classes)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('üéØ Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return predictions, pred_classes, true_classes\n",
        "\n",
        "def show_sample_predictions(model, val_gen, num_samples=8):\n",
        "    \"\"\"Display sample predictions\"\"\"\n",
        "\n",
        "    val_gen.reset()\n",
        "    images, labels = next(val_gen)\n",
        "    predictions = model.predict(images)\n",
        "\n",
        "    class_names = list(val_gen.class_indices.keys())\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "\n",
        "        true_label = class_names[np.argmax(labels[i])]\n",
        "        pred_label = class_names[np.argmax(predictions[i])]\n",
        "        confidence = np.max(predictions[i]) * 100\n",
        "\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "        plt.title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%',\n",
        "                 color=color, fontsize=9, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle('üîç Sample Predictions', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize training results\n",
        "plot_training_results(history)\n",
        "\n",
        "# Evaluate model performance\n",
        "predictions, pred_classes, true_classes = evaluate_model(model, val_gen)\n",
        "\n",
        "# Show sample predictions\n",
        "show_sample_predictions(model, val_gen)"
      ],
      "metadata": {
        "id": "X1dR30vuP8Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== FINAL RESULTS ====================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üèÜ MODEL PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_val_acc = max(history['val_accuracy'])\n",
        "best_val_loss = min(history['val_loss'])\n",
        "final_accuracy = np.mean(pred_classes == true_classes)\n",
        "\n",
        "print(f\"üéØ Final Accuracy: {final_accuracy:.3f} ({final_accuracy*100:.1f}%)\")\n",
        "print(f\"üèÜ Best Validation Accuracy: {best_val_acc:.3f} ({best_val_acc*100:.1f}%)\")\n",
        "print(f\"üìâ Best Validation Loss: {best_val_loss:.3f}\")\n",
        "print(f\"üìä Total Training Epochs: {len(history['loss'])}\")\n",
        "print(f\"‚è±Ô∏è  Training Time: {training_time:.1f} minutes\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if final_accuracy > 0.8:\n",
        "    print(\"üéâ Model achieved excellent performance!\")\n",
        "elif final_accuracy > 0.6:\n",
        "    print(\"‚úÖ Model shows good performance!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model performance could be improved.\")\n",
        "\n",
        "print(\"\\nüêæ Animal Classification Project Complete!\")\n",
        "print(\"The model successfully classifies 15 different animal species using transfer learning.\")"
      ],
      "metadata": {
        "id": "FqALVHLuWjzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}